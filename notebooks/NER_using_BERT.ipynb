{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjWKB8K2YnVx",
        "outputId": "6533b55e-668c-4cfc-fecf-e53f33d90ad4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ],
      "source": [
        "# Installing transformers library\n",
        "\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNr1lt66Z3jF",
        "outputId": "36080540-96fe-475b-e788-f0713a9c5a3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu116\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0+cu116)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n"
          ]
        }
      ],
      "source": [
        "# Installing PyTorch\n",
        "\n",
        "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4v_1NSK8YvaW"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries \n",
        "\n",
        "import pandas as pd\n",
        "import torch \n",
        "import numpy as np\n",
        "from transformers import BertTokenizerFast, BertForTokenClassification\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from torch.optim import SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Mix7jNc6Y6tV",
        "outputId": "bed9c4a8-7056-450c-cc0d-42eacac73a53"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f711eca0-24f5-46ef-bbb0-f8eeb46a03c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>47954</th>\n",
              "      <td>Opposition leader Mir Hossein Mousavi has said...</td>\n",
              "      <td>O O O B-per I-per O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47955</th>\n",
              "      <td>On Thursday , Iranian state media published a ...</td>\n",
              "      <td>O B-tim O B-gpe O O O O O O O O B-org I-org O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47956</th>\n",
              "      <td>Following Iran 's disputed June 12 elections ,...</td>\n",
              "      <td>O B-geo O O B-tim I-tim O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47957</th>\n",
              "      <td>Since then , authorities have held public tria...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47958</th>\n",
              "      <td>The United Nations is praising the use of mili...</td>\n",
              "      <td>O B-org I-org O O O O O O O O O O O O O O B-ti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f711eca0-24f5-46ef-bbb0-f8eeb46a03c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f711eca0-24f5-46ef-bbb0-f8eeb46a03c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f711eca0-24f5-46ef-bbb0-f8eeb46a03c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                    text  \\\n",
              "47954  Opposition leader Mir Hossein Mousavi has said...   \n",
              "47955  On Thursday , Iranian state media published a ...   \n",
              "47956  Following Iran 's disputed June 12 elections ,...   \n",
              "47957  Since then , authorities have held public tria...   \n",
              "47958  The United Nations is praising the use of mili...   \n",
              "\n",
              "                                                  labels  \n",
              "47954  O O O B-per I-per O O O O O O O O O O O O O O ...  \n",
              "47955  O B-tim O B-gpe O O O O O O O O B-org I-org O ...  \n",
              "47956  O B-geo O O B-tim I-tim O O O O O O O O O O O ...  \n",
              "47957          O O O O O O O O O O O O O O O O O O O O O  \n",
              "47958  O B-org I-org O O O O O O O O O O O O O O B-ti...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reading csv data\n",
        "\n",
        "df = pd.read_csv('/content/ner.csv')\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vf0tBzMXZcWx"
      },
      "outputs": [],
      "source": [
        "# Creating tokenizer intsance\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gM0zKzshZe4Q"
      },
      "outputs": [],
      "source": [
        "# Creating Dataset class\n",
        "\n",
        "label_all_tokens = False\n",
        "\n",
        "def align_label(texts, labels):\n",
        "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n",
        "\n",
        "    word_ids = tokenized_inputs.word_ids()\n",
        "\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "\n",
        "        if word_idx is None:\n",
        "            label_ids.append(-100)\n",
        "\n",
        "        elif word_idx != previous_word_idx:\n",
        "            try:\n",
        "                label_ids.append(labels_to_ids[labels[word_idx]])\n",
        "            except:\n",
        "                label_ids.append(-100)\n",
        "        else:\n",
        "            try:\n",
        "                label_ids.append(labels_to_ids[labels[word_idx]] if label_all_tokens else -100)\n",
        "            except:\n",
        "                label_ids.append(-100)\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    return label_ids\n",
        "\n",
        "class DataSequence(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        lb = [i.split() for i in df['labels'].values.tolist()]\n",
        "        txt = df['text'].values.tolist()\n",
        "        self.texts = [tokenizer(str(i),\n",
        "                               padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\") for i in txt]\n",
        "        self.labels = [align_label(i,j) for i,j in zip(txt, lb)]\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_data(self, idx):\n",
        "\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "\n",
        "        return torch.LongTensor(self.labels[idx])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_data = self.get_batch_data(idx)\n",
        "        batch_labels = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_data, batch_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffRKNjwgZjYi"
      },
      "outputs": [],
      "source": [
        "# splitting the data into train, test and validation\n",
        "# Defining Unique labels\n",
        "\n",
        "df = df[0:2000]\n",
        "\n",
        "labels = [i.split() for i in df['labels'].values.tolist()]\n",
        "unique_labels = set()\n",
        "\n",
        "for lb in labels:\n",
        "        [unique_labels.add(i) for i in lb if i not in unique_labels]\n",
        "labels_to_ids = {k: v for v, k in enumerate(unique_labels)}\n",
        "ids_to_labels = {v: k for v, k in enumerate(unique_labels)}\n",
        "\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),\n",
        "                            [int(.8 * len(df)), int(.9 * len(df))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFxm0JMpZsfK"
      },
      "outputs": [],
      "source": [
        "# Creating Model class\n",
        "\n",
        "class BertModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(BertModel, self).__init__()\n",
        "\n",
        "        self.bert = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(unique_labels))\n",
        "\n",
        "    def forward(self, input_id, mask, label):\n",
        "\n",
        "        output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68hQyuwxZvor",
        "outputId": "5d1abbf6-d81b-4198-c1af-b7b0772eb5d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100%|██████████| 800/800 [02:37<00:00,  5.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 1 | Loss:  0.530 | Accuracy:  0.869 | Val_Loss:  0.395 | Accuracy:  0.898\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 800/800 [02:36<00:00,  5.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 2 | Loss:  0.375 | Accuracy:  0.899 | Val_Loss:  0.348 | Accuracy:  0.905\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 800/800 [02:36<00:00,  5.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 3 | Loss:  0.328 | Accuracy:  0.910 | Val_Loss:  0.310 | Accuracy:  0.913\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 800/800 [02:37<00:00,  5.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 4 | Loss:  0.289 | Accuracy:  0.918 | Val_Loss:  0.293 | Accuracy:  0.917\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 800/800 [02:37<00:00,  5.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 5 | Loss:  0.254 | Accuracy:  0.928 | Val_Loss:  0.275 | Accuracy:  0.920\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 800/800 [02:37<00:00,  5.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 6 | Loss:  0.218 | Accuracy:  0.935 | Val_Loss:  0.253 | Accuracy:  0.926\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 800/800 [02:36<00:00,  5.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 7 | Loss:  0.195 | Accuracy:  0.940 | Val_Loss:  0.252 | Accuracy:  0.929\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 800/800 [02:37<00:00,  5.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 8 | Loss:  0.180 | Accuracy:  0.945 | Val_Loss:  0.244 | Accuracy:  0.929\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 800/800 [02:37<00:00,  5.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 9 | Loss:  0.166 | Accuracy:  0.950 | Val_Loss:  0.243 | Accuracy:  0.927\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 800/800 [02:37<00:00,  5.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 10 | Loss:  0.151 | Accuracy:  0.954 | Val_Loss:  0.235 | Accuracy:  0.931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 800/800 [02:37<00:00,  5.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 11 | Loss:  0.138 | Accuracy:  0.956 | Val_Loss:  0.239 | Accuracy:  0.934\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 800/800 [02:37<00:00,  5.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 12 | Loss:  0.125 | Accuracy:  0.960 | Val_Loss:  0.249 | Accuracy:  0.932\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 800/800 [02:37<00:00,  5.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 13 | Loss:  0.116 | Accuracy:  0.962 | Val_Loss:  0.245 | Accuracy:  0.934\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 800/800 [02:37<00:00,  5.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 14 | Loss:  0.101 | Accuracy:  0.966 | Val_Loss:  0.255 | Accuracy:  0.936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 800/800 [02:37<00:00,  5.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 15 | Loss:  0.095 | Accuracy:  0.969 | Val_Loss:  0.255 | Accuracy:  0.936\n"
          ]
        }
      ],
      "source": [
        "# Training the model [Transfer learning]\n",
        "\n",
        "def train_loop(model, df_train, df_val):\n",
        "\n",
        "    train_dataset = DataSequence(df_train)\n",
        "    val_dataset = DataSequence(df_val)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, num_workers=4, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, num_workers=4, batch_size=BATCH_SIZE)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    optimizer = SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    best_acc = 0\n",
        "    best_loss = 1000\n",
        "\n",
        "    for epoch_num in range(EPOCHS):\n",
        "\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        for train_data, train_label in tqdm(train_dataloader):\n",
        "\n",
        "            train_label = train_label.to(device)\n",
        "            mask = train_data['attention_mask'].squeeze(1).to(device)\n",
        "            input_id = train_data['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss, logits = model(input_id, mask, train_label)\n",
        "\n",
        "            for i in range(logits.shape[0]):\n",
        "\n",
        "              logits_clean = logits[i][train_label[i] != -100]\n",
        "              label_clean = train_label[i][train_label[i] != -100]\n",
        "\n",
        "              predictions = logits_clean.argmax(dim=1)\n",
        "              acc = (predictions == label_clean).float().mean()\n",
        "              total_acc_train += acc\n",
        "              total_loss_train += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        total_acc_val = 0\n",
        "        total_loss_val = 0\n",
        "\n",
        "        for val_data, val_label in val_dataloader:\n",
        "\n",
        "            val_label = val_label.to(device)\n",
        "            mask = val_data['attention_mask'].squeeze(1).to(device)\n",
        "            input_id = val_data['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            loss, logits = model(input_id, mask, val_label)\n",
        "\n",
        "            for i in range(logits.shape[0]):\n",
        "\n",
        "              logits_clean = logits[i][val_label[i] != -100]\n",
        "              label_clean = val_label[i][val_label[i] != -100]\n",
        "\n",
        "              predictions = logits_clean.argmax(dim=1)\n",
        "              acc = (predictions == label_clean).float().mean()\n",
        "              total_acc_val += acc\n",
        "              total_loss_val += loss.item()\n",
        "\n",
        "        val_accuracy = total_acc_val / len(df_val)\n",
        "        val_loss = total_loss_val / len(df_val)\n",
        "\n",
        "        print(\n",
        "            f'Epochs: {epoch_num + 1} | Loss: {total_loss_train / len(df_train): .3f} | Accuracy: {total_acc_train / len(df_train): .3f} | Val_Loss: {total_loss_val / len(df_val): .3f} | Accuracy: {total_acc_val / len(df_val): .3f}')\n",
        "\n",
        "LEARNING_RATE = 5e-3\n",
        "EPOCHS = 15\n",
        "BATCH_SIZE = 2\n",
        "\n",
        "model = BertModel()\n",
        "train_loop(model, df_train, df_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flo7qqd6ZzKS",
        "outputId": "1c27a91e-f4be-402d-b462-bcf19f11250b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy:  0.946\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model\n",
        "\n",
        "def evaluate(model, df_test):\n",
        "\n",
        "    test_dataset = DataSequence(df_test)\n",
        "\n",
        "    test_dataloader = DataLoader(test_dataset, num_workers=4, batch_size=1)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0.0\n",
        "\n",
        "    for test_data, test_label in test_dataloader:\n",
        "\n",
        "            test_label = test_label.to(device)\n",
        "            mask = test_data['attention_mask'].squeeze(1).to(device)\n",
        "\n",
        "            input_id = test_data['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            loss, logits = model(input_id, mask, test_label)\n",
        "\n",
        "            for i in range(logits.shape[0]):\n",
        "\n",
        "              logits_clean = logits[i][test_label[i] != -100]\n",
        "              label_clean = test_label[i][test_label[i] != -100]\n",
        "\n",
        "              predictions = logits_clean.argmax(dim=1)\n",
        "              acc = (predictions == label_clean).float().mean()\n",
        "              total_acc_test += acc\n",
        "\n",
        "    val_accuracy = total_acc_test / len(df_test)\n",
        "    print(f'Test Accuracy: {total_acc_test / len(df_test): .3f}')\n",
        "\n",
        "\n",
        "evaluate(model, df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFaET41rcmxA",
        "outputId": "b6a1b85e-1dc0-447b-b3fc-176c427982b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bill Gates is the founder of Microsoft\n",
            "['B-per', 'I-per', 'O', 'O', 'O', 'O', 'B-org']\n"
          ]
        }
      ],
      "source": [
        "# Predicting a sentence\n",
        "\n",
        "def align_word_ids(texts):\n",
        "  \n",
        "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n",
        "\n",
        "    word_ids = tokenized_inputs.word_ids()\n",
        "\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "\n",
        "        if word_idx is None:\n",
        "            label_ids.append(-100)\n",
        "\n",
        "        elif word_idx != previous_word_idx:\n",
        "            try:\n",
        "                label_ids.append(1)\n",
        "            except:\n",
        "                label_ids.append(-100)\n",
        "        else:\n",
        "            try:\n",
        "                label_ids.append(1 if label_all_tokens else -100)\n",
        "            except:\n",
        "                label_ids.append(-100)\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    return label_ids\n",
        "\n",
        "\n",
        "def evaluate_one_text(model, sentence):\n",
        "\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    text = tokenizer(sentence, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    mask = text['attention_mask'].to(device)\n",
        "    input_id = text['input_ids'].to(device)\n",
        "    label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n",
        "\n",
        "    logits = model(input_id, mask, None)\n",
        "    logits_clean = logits[0][label_ids != -100]\n",
        "\n",
        "    predictions = logits_clean.argmax(dim=1).tolist()\n",
        "    prediction_label = [ids_to_labels[i] for i in predictions]\n",
        "    print(sentence)\n",
        "    print(prediction_label)\n",
        "            \n",
        "evaluate_one_text(model, 'Bill Gates is the founder of Microsoft')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4PyFZGgctt0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.15 (default, Nov 24 2022, 14:38:14) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "e87c311b38e3867b44965d1fc544340be30d9bb75864c35cc64a91cfbbf57e74"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
